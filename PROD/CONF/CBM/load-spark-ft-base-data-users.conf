flux.yarn.queue = "compute"
flux.log-level = "ERROR"

flux.input-type = "HIVE"
flux.output-type = "HIVE"

flux.spark.setup-conf = []

flux.setup-conf = []

flux.spark.setup-conf += {"key": "spark.sql.crossJoin.enabled", "value": "true"}
flux.spark.setup-conf += {"key": "hive.exec.dynamic.partition.mode","value": "nonstrict"}
flux.spark.setup-conf += {"key": "spark.sql.files.ignoreCorruptFiles","value": "true"}
flux.spark.setup-conf += {"key": "spark.debug.maxToStringFields","value": "true"} 


flux.name = "LOAD_SPARK_FT_BASE_DATA_USERS"

flux.has-date-processing = true

flux.slice-value-type = "DAILY"
flux.slice-begin-value = -7
flux.slice-end-value = -1
flux.slice-step-value = 1
flux.slice-begin-value-offset = 0
flux.slice-end-value-offset = 0
flux.slice-has-state-query=true
flux.slice-state-query="""
select
if(count(*)=44,'OK','NOK')
from dim.dt_dates
where datecode between date_sub(current_date, 44) and date_sub(current_date, 1)
and datecode in (select distinct event_date from MON.SPARK_FT_BASE_DATA_USERS where event_date between date_sub(current_date, 44) and date_sub(current_date, 1))
"""
flux.slice-has-filter-query = true
flux.slice-filter-query = """
select
date_format(datecode,'yyyy-MM-dd')
from dim.dt_dates
where datecode between date_sub(current_date, 44) and date_sub(current_date, 1)
and datecode in (select distinct event_date from MON.SPARK_FT_BASE_DATA_USERS where event_date between date_sub(current_date, 44) and date_sub(current_date, 1))
"""
flux.slice-date-format = "yyyy-MM-dd"

flux.has-pre-queries = true
flux.has-exec-queries = true
flux.has-post-queries = false

flux.inline.exec-queries += "add jar hdfs:///PROD/UDF/hive-udf-1.0.jar"
flux.inline.exec-queries += "DROP TEMPORARY  FUNCTION IF EXISTS GET_NNP_MSISDN_9DIGITS"
flux.inline.exec-queries += "create temporary function GET_NNP_MSISDN_9DIGITS as 'cm.orange.bigdata.udf.GetNnpMsisdn9Digits'"

flux.inline.pre-exec-queries += """
SELECT IF(
T_1.ft_tab = 0
AND T_11.ft_tab > 0
AND T_2.ft_tab > 0
, 'OK'
, 'NOK'
)
FROM
(SELECT COUNT(*) ft_tab FROM MON.SPARK_FT_BASE_DATA_USERS WHERE event_date='###SLICE_VALUE###') T_1,
(SELECT COUNT(*) ft_tab FROM MON.SPARK_ALL_DATA_USERS_DAILY WHERE event_date='###SLICE_VALUE###') T_11,
(SELECT COUNT(*) ft_tab FROM MON.SPARK_FT_DATA_USER_CBM WHERE event_date='###SLICE_VALUE###') T_2
"""


flux.inline.exec-queries += """
INSERT INTO MON.SPARK_FT_BASE_DATA_USERS
SELECT 
A.msisdn,
A.volume_data_in,
A.user_data,
CASE WHEN A.Volume_4G IS NULL THEN 0
ELSE A.Volume_4G END AS Volume_4G,
A.user_4G,
CASE WHEN A.Volume_3G IS NULL THEN 0
ELSE A.Volume_3G END AS Volume_3G,
CASE WHEN A.Volume_2G IS NULL THEN 0
ELSE A.Volume_2G END AS Volume_2G,
A.mou,
A.arpu, 
A.arpu_data,
A.Arpu_voix,
A.activation_date,
A.group_user,
CASE WHEN A.region IS NULL THEN "z. Non localise"
ELSE A.region END AS region,
CASE WHEN A.region_v2 IS NULL THEN "z. Non localise"
ELSE A.region_v2 END AS region_v2,
CASE WHEN A.type_zone2 IS NULL THEN "Inconnu"
ELSE A.type_zone2 END AS type_zone2,
CASE WHEN B.volume_data_in IS NULL THEN 0
ELSE B.volume_data_in END AS volume_data_in_j,
CASE WHEN B.user_data IS NULL THEN 0
ELSE B.user_data END AS user_data_j,
CASE WHEN B.Volume_4G IS NULL THEN 0
ELSE B.Volume_4G END AS Volume_4G_j,
CASE WHEN B.user_4G IS NULL THEN 0
ELSE B.user_4G END AS user_4G_j,
CASE WHEN B.volume_3G IS NULL THEN 0
ELSE B.volume_3G END AS volume_3G_j,
CASE WHEN B.volume_2G IS NULL THEN 0
ELSE B.volume_2G END AS volume_2G_j,
CASE WHEN B.mou IS NULL THEN 0
ELSE B.mou END AS mou_j,  
CASE WHEN B.arpu IS NULL THEN 0
ELSE B.arpu END AS arpu_j,  
CASE WHEN B.arpu_data IS NULL THEN 0
ELSE B.arpu_data END AS arpu_data_j, 
CASE WHEN B.arpu_voix IS NULL THEN 0
ELSE B.arpu_voix END AS arpu_voix_j, 
A.event_date AS event_date
FROM
(
SELECT * FROM MON.SPARK_ALL_DATA_USERS_DAILY
WHERE EVENT_DATE = '###SLICE_VALUE###'
) A 
LEFT JOIN
(
SELECT * FROM MON.SPARK_FT_DATA_USER_CBM
WHERE EVENT_DATE = '###SLICE_VALUE###'
) B 
ON GET_NNP_MSISDN_9DIGITS(A.msisdn) = GET_NNP_MSISDN_9DIGITS(B.msisdn)
"""
