  // Key words
  ###SLICE_VALUE###, ###START_SLICE_VALUE###, ###END_SLICE_VALUE###

  flux.yarn.queue = "PROD"
  flux.log-level = "ERROR"

  flux.name = "NOTIFICATION_REVENUE_IN" // Required: Corresponds to the instance ID

  flux.has-date-processing = true

  flux.slice-value-type = "DAILY" // Possible values are // QUARTER-HOURLY ,HALF-HOURLY ,HOURLY (YYYYMMDD HH24), DAILY (YYYYMMDD), MONTHLY (YYYYMM), YEARLY (YYYYMM)
  flux.slice-begin-value = -14
  flux.slice-end-value = -1
  flux.slice-step-value = 1
  flux.slice-begin-value-offset = 0
  flux.slice-end-value-offset = 0
  flux.slice-date-format = "yyyy-MM-dd"//"yyyy-MM-dd HH:mm:ss"


  flux.pre-query.execution.mode = "HIVE"  // Or HIVE
  flux.exec-query.execution.mode = "HIVE"  // Or HIVE
  flux.post-query.execution.mode = "HIVE"  // Or HIVE

  flux.has-pre-queries = false
  flux.has-exec-queries = true
  flux.has-post-queries = false


  flux.exec-queries += "/DATALAB/CONF/notif_revenue.hql"
  flux.spool-to-file = true
  flux.spool-file-prefix = "REVENUE_IN_"
  flux.spool-file-suffix = ".csv"
  flux.spool-file-separator = "|"
  flux.spool-file-add-date = true
  flux.spool-file-date-format = "yyyyMMdd"
  flux.spool-file-hdfs-dir = "/DATALAB/SPOOL"
  flux.spool-file-is-compress = false


  flux.hive.extra-conf += "--hiveconf hive.exec.dynamic.partition=true"
  flux.hive.extra-conf += "--hiveconf hive.exec.dynamic.partition.mode=nonstrict"
  flux.hive.extra-conf += "--hiveconf hive.enforce.bucketing=true"


