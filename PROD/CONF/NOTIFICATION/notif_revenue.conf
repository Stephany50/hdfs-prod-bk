// Key words
###SLICE_VALUE###, ###START_SLICE_VALUE###, ###END_SLICE_VALUE###

flux.yarn.queue = "PROD"
flux.log-level = "ERROR"

flux.name = "NOTIFICATION_REVENUE_IN" // Required: Corresponds to the instance ID

flux.has-date-processing = true
flux.spool-file-prefix="REVENUE_IN_"

flux.slice-value-type = "DAILY" // Possible values are // QUARTER-HOURLY ,HALF-HOURLY ,HOURLY (YYYYMMDD HH24), DAILY (YYYYMMDD), MONTHLY (YYYYMM), YEARLY (YYYYMM)
flux.slice-begin-value = -14
flux.slice-end-value = -1
flux.slice-step-value = 1
flux.slice-begin-value-offset = 0
flux.slice-end-value-offset = 0
flux.slice-date-format = "yyyy-MM-dd"//"yyyy-MM-dd HH:mm:ss"


flux.pre-query.execution.mode = "JDBC"  // Or HIVE
flux.exec-query.execution.mode = "JDBC"  // Or HIVE
flux.post-query.execution.mode = "JDBC"  // Or HIVE

flux.has-pre-queries = true
flux.has-exec-queries = true

flux.pre-exec-queries+="SELECT 'OK'"
flux.inline.exec-queries +="SELECT * FROM REPORT.FT_GLOBAL_ACTIVITY_DAILY WHERE TRANSACTION_DATE='###SLICE_VALUE###'"


flux.spool-to-file = true
flux.spool-file-add-date = true
flux.spool-file-is-compress = false

flux.hive.extra-conf += "--hiveconf hive.exec.dynamic.partition=true"
flux.hive.extra-conf += "--hiveconf hive.exec.dynamic.partition.mode=nonstrict"
flux.hive.extra-conf += "--hiveconf hive.enforce.bucketing=true"

// Prequery variables
flux.parallel-size = 1