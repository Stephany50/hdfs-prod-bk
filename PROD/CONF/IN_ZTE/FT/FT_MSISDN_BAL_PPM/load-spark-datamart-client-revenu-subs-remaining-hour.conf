
flux.yarn.queue = "compute"
flux.log-level = "ERROR"

flux.input-type = "HIVE"
flux.output-type = "HIVE"

flux.spark.setup-conf = []

flux.setup-conf = []

flux.spark.setup-conf += {"key": "spark.sql.crossJoin.enabled", "value": "true"}
flux.spark.setup-conf += {"key": "hive.exec.dynamic.partition.mode","value": "nonstrict"}

flux.name = "DATAMART_CLIENT_REVENU_SUBS_REMAINING_HOUR"

flux.has-date-processing = true

flux.slice-value-type = "DAILY"
flux.slice-begin-value = -172
flux.slice-end-value = -1
flux.slice-step-value = 1
flux.slice-begin-value-offset = 0
flux.slice-end-value-offset = 0
flux.slice-has-state-query=false
flux.slice-state-query="""
select
    if(count(*)=20,'OK','NOK')
from dim.dt_dates
where datecode between date_sub(current_date, 20) and date_sub(current_date, 1)
    and datecode in (select distinct event_date from tmp.datamart_client_revenu_subs_hour where event_date between date_sub(current_date, 20) and date_sub(current_date, 1))
"""
flux.slice-has-filter-query = false
flux.slice-filter-query = """
select
    date_format(datecode,'yyyy-MM-dd')
from dim.dt_dates
where datecode between date_sub(current_date, 20) and date_sub(current_date, 1)
    and datecode in (select distinct event_date from tmp.datamart_client_revenu_subs_hour where event_date between date_sub(current_date, 20) and date_sub(current_date, 1))
"""
flux.slice-date-format = "yyyy-MM-dd"

flux.has-pre-queries = true
flux.has-exec-queries = true
flux.has-post-queries = false

flux.inline.pre-exec-queries += """
SELECT IF(
    T_1.FT_EXISTS = 0
    AND T_2.FT_EXISTS > 1
    AND T_3.FT_EXISTS > 1
    AND T_4.FT_EXISTS > 1
    AND T_5.FT_EXISTS > 1
    , 'OK'
    , 'NOK'
)
FROM
(SELECT COUNT(*) FT_EXISTS FROM tmp.datamart_client_revenu_subs_remaining_hour WHERE EVENT_DATE='###SLICE_VALUE###') T_1,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_da_status WHERE EVENT_DATE='###SLICE_VALUE###') T_2,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_bal_usage_day WHERE EVENT_DATE='###SLICE_VALUE###') T_3,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_bal_ppm WHERE EVENT_DATE='###SLICE_VALUE###') T_4,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_bal_constants WHERE EVENT_DATE='###SLICE_VALUE###') T_5
"""

flux.inline.exec-queries += """

insert into tmp.datamart_client_revenu_subs_remaining_hour
select
    z0.msisdn
    , z1.site_name
    , '23' hour_period
    , revenu_subs_data
    , revenu_subs_voix
    , revenu_subs_sms
    , other_subs_revenu
    , current_timestamp insert_date
    , '###SLICE_VALUE###' event_date
from
(
    select
        msisdn
        , sum(case when da_type = 'DATA' then revenu_remaining else 0 end) revenu_subs_data
        , sum(case when da_type = 'TEL' then revenu_remaining else 0 end) revenu_subs_voix
        , sum(case when da_type = 'SMS' then revenu_remaining else 0 end) revenu_subs_sms
        , sum(case when da_type not in ('DATA', 'TEL', 'SMS') then revenu_remaining else 0 end) other_subs_revenu
    from
    (
        select
            a.msisdn
            , a.bal_id
            , da_type
            , nvl(bal_revenu, 0) - (nvl(revenu_already_dispatched, 0) + nvl(ppm, 0)*(nvl(sum_conso_until_day, 0) - nvl(sum_conso_until_yesterday, 0))) revenu_remaining
        from
        (
            select
                msisdn
                , bal_id
                , da_type
            from mon.spark_ft_msisdn_da_status
            where event_date = '###SLICE_VALUE###' and expiry_date = '###SLICE_VALUE###'
        ) a
        left join
        (
            select
                msisdn
                , bal_id
                , ppm
                , revenu_already_dispatched
            from mon.spark_ft_msisdn_bal_ppm
            where event_date = '###SLICE_VALUE###'
        ) b on a.msisdn = b.msisdn and a.bal_id = b.bal_id
        left join
        (
            select
                msisdn
                , bal_id
                , sum_conso_until_day
                , sum_conso_until_yesterday
            from mon.spark_ft_msisdn_bal_usage_day
            where event_date = '###SLICE_VALUE###'
        ) c on a.msisdn = c.msisdn and a.bal_id = c.bal_id
        left join
        (
            select
                msisdn
                , bal_id
                , bal_revenu
            from mon.spark_ft_msisdn_bal_constants
            where event_date = '###SLICE_VALUE###'
        ) d on a.msisdn = d.msisdn and a.bal_id = d.bal_id
    ) z
    group by msisdn
) z0
left join
(
    select
        msisdn
        , SITE_NAME
    from mon.spark_ft_client_site_traffic_hour
    where event_date = '###SLICE_VALUE###' and hour_period = '23'
) z1 on z0.msisdn = z1.msisdn
"""

