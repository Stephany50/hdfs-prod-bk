
flux.yarn.queue = "compute"
flux.log-level = "ERROR"

flux.input-type = "HIVE"
flux.output-type = "HIVE"

flux.spark.setup-conf = []

flux.setup-conf = []

flux.spark.setup-conf += {"key": "spark.sql.crossJoin.enabled", "value": "true"}
flux.spark.setup-conf += {"key": "hive.exec.dynamic.partition.mode","value": "nonstrict"}

flux.name = "LOAD_SPARK_TMP_DATAMART_CLIENT_REVENU_SUBS_HOUR"

flux.has-date-processing = true

flux.slice-value-type = "DAILY"
flux.slice-begin-value = -100
flux.slice-end-value = -68
flux.slice-step-value = 1
flux.slice-begin-value-offset = 0
flux.slice-end-value-offset = 0
flux.slice-has-state-query=false
flux.slice-state-query="""
select
    if(count(*)=20,'OK','NOK')
from dim.dt_dates
where datecode between date_sub(current_date, 20) and datspark_ft_msisdn_subs_bal e_sub(current_date, 1)
    and datecode in (select distinct event_date from tmp.datamart_client_revenu_subs_hour where event_date between date_sub(current_date, 20) and date_sub(current_date, 1))
"""
flux.slice-has-filter-query = false
flux.slice-filter-query = """
select
    date_format(datecode,'yyyy-MM-dd')
from dim.dt_dates
where datecode between date_sub(current_date, 20) and date_sub(current_date, 1)
    and datecode in (select distinct event_date from tmp.datamart_client_revenu_subs_hour where event_date between date_sub(current_date, 20) and date_sub(current_date, 1))
"""
flux.slice-date-format = "yyyy-MM-dd"

flux.has-pre-queries = true
flux.has-exec-queries = true
flux.has-post-queries = false

flux.inline.pre-exec-queries += """
SELECT IF(
    T_1.FT_EXISTS = 0
    AND T_2.FT_EXISTS > 1
    AND T_3.FT_EXISTS > 1
    AND T_4.FT_EXISTS > 1
    AND T_5.FT_EXISTS > 1
    AND T_6.FT_EXISTS > 1
    , 'OK'
    , 'NOK'
)
FROM
(SELECT COUNT(*) FT_EXISTS FROM tmp.datamart_client_revenu_subs_hour WHERE EVENT_DATE='###SLICE_VALUE###') T_1,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_subs_bal WHERE EVENT_DATE='###SLICE_VALUE###') T_2,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_bal_usage_hour WHERE EVENT_DATE='###SLICE_VALUE###') T_3,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_bal_ppm WHERE EVENT_DATE='###SLICE_VALUE###') T_4,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_client_site_traffic_hour WHERE EVENT_DATE='###SLICE_VALUE###') T_5,
(SELECT COUNT(*) FT_EXISTS FROM mon.spark_ft_msisdn_revenu_for_daily_drop_subs WHERE EVENT_DATE='###SLICE_VALUE###') T_6
"""

flux.inline.exec-queries += """
insert into tmp.datamart_client_revenu_subs_hour
select
    a.msisdn
    , a.site_name
    , a.hour_period
    , nvl(revenu_subs_data, 0) revenu_subs_data
    , nvl(revenu_subs_voix, 0) revenu_subs_voix
    , nvl(revenu_subs_sms, 0) revenu_subs_sms
    , nvl(other_subs_revenu, 0) other_subs_revenu
    , current_timestamp insert_date
    , '###SLICE_VALUE###' event_date
from
(
    select
        msisdn
        , hour_period
        , sum(revenu_subs_data) revenu_subs_data
        , sum(revenu_subs_voix) revenu_subs_voix
        , sum(revenu_subs_sms) revenu_subs_sms
        , sum(other_subs_revenu) other_subs_revenu
    from
    (
        select
            d.msisdn
            , d.hour_period
            , sum(case when service = 'DATA' then volume_to_valorise*nvl(ppm, 0) else 0 end) revenu_subs_data
            , sum(case when service = 'TEL' then volume_to_valorise*nvl(ppm, 0) else 0 end) revenu_subs_voix
            , sum(case when service = 'SMS' then volume_to_valorise*nvl(ppm, 0) else 0 end) revenu_subs_sms
            , sum(case when service = 'OTHER' then volume_to_valorise*nvl(ppm, 0) else 0 end) other_subs_revenu
        FROM
        (
            select
                d1.msisdn
                , d1.bal_id
                , d1.hour_period
                , d1.service
                , sum(used_volume) volume_to_valorise
            from
            (
                select
                    msisdn
                    , bal_id
                    , TRANSACTION_TIME
                from
                (
                    select
                        msisdn
                        , bal_id
                        , TRANSACTION_TIME
                        , bdle_name
                        , BEN_ACCT_ID
                        , row_number() over(partition by msisdn, bal_id order by TRANSACTION_TIME desc) line_number
                    from mon.spark_ft_msisdn_subs_bal
                    where event_date = '###SLICE_VALUE###'
                ) d00
                left join dim.dt_politique_forfaits d01 on trim(upper(d00.bdle_name)) = trim(upper(d01.OFFER_NAME)) and d00.BEN_ACCT_ID = d01.std_code
                where upper(d01.politic) = 'ECRASE' and d00.line_number = 1
            ) d0
            right join
            (
                select
                    msisdn
                    , bal_id
                    , hour_period
                    , used_volume
                    , service
                from mon.spark_ft_msisdn_bal_usage_hour
                where event_date = '###SLICE_VALUE###'
            ) d1 on d0.msisdn = d1.msisdn and d0.bal_id = d1.bal_id
            where hour_period >= nvl(substr(TRANSACTION_TIME, 1, 2), '00')
            group by d1.msisdn, d1.bal_id, d1.hour_period, d1.service
        ) d
        left join
        (
            select
                msisdn
                , bal_id
                , ppm
            from mon.spark_ft_msisdn_bal_ppm
            where event_date = '###SLICE_VALUE###'
        ) a on a.msisdn = d.msisdn and a.bal_id = d.bal_id
        group by d.msisdn, d.hour_period
        union all
        select
            msisdn
            , '23' hour_period
            , revenu_data_per_day revenu_subs_data
            , revenu_voix_per_day revenu_subs_voix
            , revenu_sms_per_day revenu_subs_sms
            , other_revenu_per_day other_subs_revenu
        from mon.spark_ft_msisdn_revenu_for_daily_drop_subs
        where event_date = '###SLICE_VALUE###'
    ) b0
    group by msisdn, hour_period
) b
left join
(
    select *
    from mon.spark_ft_client_site_traffic_hour
    where event_date = '###SLICE_VALUE###'
) a
on a.msisdn = b.msisdn and a.hour_period = b.hour_period
"""

